# Звіт про Профілювання Продуктивності Веб-додатку Притулку для тварин

## 1. Методологія Профілювання

### 1.1. Досліджені Інструменти Профілювання

Для профілювання продуктивності веб-додатку "Притулок для тварин", розробленого на **Python** з використанням фреймворку **Flask**, були розглянуті та застосовані наступні інструменти:

* **CPU Профілювання:**

    * **`cProfile` (вбудований модуль Python):** Стандартний і найпопулярніший профайлер, що дозволяє отримати детальний звіт про час, витрачений кожною функцією та її дочірніми викликами. Його було інтегровано безпосередньо в код роуту `/` для автоматичного профілювання кожного запиту до головної сторінки.

    * **`Flask-DebugToolbar` (для розробки):** Хоча не використовувався для збору фінальних даних у цьому звіті, він є чудовим інтерактивним інструментом для моніторингу запитів до бази даних, часу виконання та інших метрик безпосередньо в браузері під час розробки.

* **Моніторинг Пам'яті:**

    * **`memory_profiler` (стороння бібліотека):** Розглядався для вимірювання використання пам'яті по рядках коду. Проте, для базового профілювання, що вимагалося, і враховуючи простоту додатка, його детальний вивід не було використано для фінального аналізу, оскільки використання пам'яті виявилося мінімальним.

    * **`resource` (вбудований модуль Unix-подібних систем):** Надає загальну інформацію про використання системних ресурсів, але є менш деталізованим для програмного профілювання пам'яті.

* **Профілювання Запитів до БД:**

    * **Вбудоване логування:** Налаштоване логування дозволяє відстежувати час виконання операцій з БД, оскільки всі взаємодії з SQLite обгорнуті в `try...except` блоки.

    * **`cProfile` вивід:** Звіт `cProfile` безпосередньо показує час, витрачений на методи `sqlite3.Connection.execute`, що дозволяє ідентифікувати "гарячі точки" на рівні взаємодії з базою даних.

### 1.2. Ключові Метрики Продуктивності

Для оцінки продуктивності проєкту були визначені наступні ключові метрики:

* **Час відгуку сторінки (Page Load Time):** Загальний час, необхідний для повного завантаження веб-сторінки у браузері.

* **Час виконання запитів до бази даних:** Тривалість виконання SQL-запитів.

* **Використання CPU:** Відсоток використання процесора під час обробки запитів додатком (оцінюється за допомогою `cProfile`).

* **Кількість SQL-запитів на сторінку:** Загальна кількість запитів, що виконуються для рендерингу однієї сторінки.

### 1.3. Тестові Сценарії та Набір Даних

Для отримання реалістичних даних про продуктивність, було розроблено та виконано наступні тестові сценарії на базі попередньо підготовлених даних:

**Набір Даних:**
Для імітації реального середовища, за допомогою допоміжного скрипта `populate_db.py` було згенеровано та додано **500 фейкових записів про тварин** до бази даних `shelter.db`. Також було створено два фейкові облікові записи користувачів ("admin", "user") для тестування автентифікованих операцій.

**Тестові Сценарії:**

1.  **Завантаження головної сторінки (`/`):** Багаторазове відвідування головної сторінки анонімним користувачем, включаючи навігацію по пагінації та, за бажанням, використання фільтрів/пошуку. Це основний сценарій для профілювання за допомогою `cProfile`.

2.  **Перегляд деталей тварини (`/animal/<id>`):** Завантаження детальної сторінки для кількох існуючих тварин.

3.  **Додавання нової тварини (`/add`):** Вхід як автентифікований користувач та спроба додати нову тварину з заповненням всіх полів та завантаженням фейкового файлу зображення.

4.  **Вхід користувача (`/login`):** Профілювання часу, необхідного для успішної автентифікації користувача.

## 2. Зібрані Метрики та Результати Профілювання

Профілювання проводилося шляхом запуску `main.py` та взаємодії з веб-інтерфейсом додатку. Результати `cProfile` логувалися у консоль та файл `app.log`.

### 2.1. Час Виконання Ключових Операцій

(Наведені дані базуються на отриманих логах та є типовими для даного додатка на невеликих обсягах даних. Час може незначно відрізнятися в залежності від апаратного забезпечення.)

* **Завантаження головної сторінки (`/`)**:

    * **CPU Time (cumtime)**: ~0.001 - 0.002 секунди (1-2 мілісекунди).

    * **Page Load Time (browser)**: Зазвичай < 100 мс (не вимірювалося інструментально, оцінка візуально).

    * **Кількість SQL-запитів:** 3 (`COUNT(id)`, `SELECT * FROM animals`, `SELECT DISTINCT type`).

* **Перегляд деталей тварини (`/animal/<id>`):**

    * **CPU Time (cumtime)**: ~0.001 секунди.

    * **Кількість SQL-запитів:** 1 (`SELECT * FROM animals WHERE id = ?`).

* **Додавання нової тварини (`/add`):**

    * **CPU Time (cumtime)**: ~0.005 - 0.015 секунди (час може зростати зі збільшенням розміру файлу зображення).

    * **Кількість SQL-запитів:** 1 (`INSERT INTO animals`).

* **Вхід користувача (`/login`):**

    * **CPU Time (cumtime)**: ~0.001 секунди.

    * **Кількість SQL-запитів:** 1 (`SELECT * FROM users`).

### 2.2. Результати Профілювання CPU (`cProfile`)

Нижче наведено типовий фрагмент звіту `cProfile` для завантаження головної сторінки (`/`), відсортований за кумулятивним часом. Ці дані показують, які функції сукупно займають найбільше часу виконання.


--- CPU Профіль для '/':
317 function calls (302 primitive calls) in 0.002 seconds

Ordered by: cumulative time
List reduced from 100 to 10 due to restriction <10>
````
ncalls  tottime  percall  cumtime  percall filename:lineno(function)
3    0.001    0.000    0.001    0.000 {method 'execute' of 'sqlite3.Connection' objects}
1    0.000    0.000    0.000    0.000 ...PycharmProjects\HrytsenkoMaksym\app.py:127(get_db_connection)
1    0.000    0.000    0.000    0.000 {built-in method _sqlite3.connect}
1    0.000    0.000    0.000    0.000 ...PycharmProjects\HrytsenkoMaksym\app.py:167(get_log_context)
20/7    0.000    0.000    0.000    0.000 ...PycharmProjects\Diplom.venv1\lib\site-packages\werkzeug\local.py:310(get)
6/5    0.000    0.000    0.000    0.000 ...PycharmProjects\Diplom.venv1\lib\site-packages\werkzeug\utils.py:95(get)
1    0.000    0.000    0.000    0.000 ...PycharmProjects\Diplom.venv1\lib\site-packages\werkzeug\sansio\request.py:204(url)
1    0.000    0.000    0.000    0.000 ...PycharmProjects\Diplom.venv1\lib\site-packages\werkzeug\sansio\utils.py:105(get_current_url)
2    0.000    0.000    0.000    0.000 ...PycharmProjects\Diplom.venv1\lib\site-packages\werkzeug\local.py:525(_get_current_object)
2    0.000    0.000    0.000    0.000 ...PycharmProjects\Diplom.venv1\lib\site-packages\flask_login\utils.py:25()

````

### 2.3. Виявлені "Гарячі Точки"

На основі проведеного профілювання, основними "гарячими точками" (функціями, що займають найбільше кумулятивного часу виконання) є:

1.  **Виконання SQL-запитів (`{method 'execute' of 'sqlite3.Connection' objects}`)**: Це є найбільш ресурсомісткою операцією. На головній сторінці виконуються три запити до бази даних (підрахунок загальної кількості тварин, вибірка тварин для поточної сторінки та вибірка унікальних типів тварин). Незважаючи на те, що ці запити займають найбільше часу порівняно з іншими функціями, **абсолютний час виконання є вкрай низьким (близько 1 мілісекунди)**, що свідчить про високу ефективність на поточному обсязі даних.

2.  **Встановлення з'єднання з базою даних (`main.py:get_db_connection` та `{built-in method _sqlite3.connect}`)**: Хоча час, витрачений на встановлення з'єднання, дуже малий, ця операція виконується для кожного запиту до БД. У масштабованих додатках, це може стати "вузьким місцем" через накладні витрати на підключення.

3.  **Отримання контексту логування (`main.py:get_log_context`) та внутрішні функції Flask/Werkzeug/Flask-Login**: Ці функції виконуються часто, але їхній індивідуальний та сукупний внесок у загальний час виконання є мінімальним. Їхня присутність у топі свідчить про загальну швидкість виконання інших частин коду.

## 3. Аналіз Продуктивності та Рекомендації

### 3.1. Виявлені Проблеми з Продуктивністю

На поточному етапі розробки та з використанням 500 записів у базі даних, **значних проблем з продуктивністю не виявлено**. Додаток демонструє дуже низький час відгуку (кілька мілісекунд для ключових операцій) та ефективно використовує CPU. Використання пам'яті також знаходиться на мінімальному рівні, типовому для Flask-додатків.

### 3.2. Рекомендації щодо Подальшої Оптимізації (з урахуванням масштабування)

Хоча поточна продуктивність є задовільною, існують потенційні області для оптимізації, які стануть більш актуальними зі зростанням обсягу даних або навантаження на додаток:

* **Оптимізація запитів до БД та індексування:**

    * Для таблиці `animals` рекомендується створити **індекси** на стовпцях `type` та `date_added`, оскільки вони використовуються у фільтрації (`type`) та сортуванні (`date_added`). Це прискорить операції `SELECT` та `ORDER BY` при великих обсягах даних.

    * Регулярно перевіряйте складніші запити на `N+1` проблеми, хоча у поточному коді таких явних проблем не виявлено.

* **Керування з'єднаннями з БД:**

    * У виробничих середовищах замість відкриття та закриття нового з'єднання `sqlite3` для кожного запиту, варто розглянути використання **пулів з'єднань з базою даних** (наприклад, через SQLAlchemy ORM з пулом). Це зменшить накладні витрати на встановлення з'єднань, що може бути значним при великій кількості одночасних запитів.

* **Кешування:**

    * Для сторінок, які генеруються рідко або мають незмінний вміст (наприклад, список типів тварин), можна розглянути **кешування** (наприклад, з `Flask-Caching`). Це дозволить уникнути повторних запитів до БД та обчислень.

* **Оптимізація обробки зображень:**

    * Якщо розмір завантажуваних зображень буде значним, варто інтегрувати функціонал для **стиснення та зміни розміру зображень** під час завантаження. Це зменшить обсяг даних на диску та прискорить завантаження сторінок для користувачів.

**Висновок:**
Поточна реалізація демонструє базовий рівень продуктивності, прийнятний для малого та середнього масштабу. Виявлені "гарячі точки" типові для додатків, що інтенсивно взаємодіють з базою даних. Подальша оптимізація повинна бути зосереджена на ефективності запитів до БД та управлінні ресурсами в міру зростання вимог та навантаження на додаток.
